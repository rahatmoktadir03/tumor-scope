
import streamlit as st
import tensorflow as tf
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing import image
import numpy as np
import plotly.graph_objects as go
import cv2
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Dropout, Flatten
from tensorflow.keras.optimizers import Adamax
from tensorflow.keras.metrics import Precision, Recall
import google.generativeai as genai
from dotenv import load_dotenv
import PIL.Image
import os

# Load environment variables
load_dotenv()
genai.configure(api_key=st.secrets["GOOGLE_API_KEY"])

output_dir = 'saliency_maps'
os.makedirs(output_dir, exist_ok=True)

labels = ['Glioma', 'Meningioma', 'No tumor', 'Pituitary']

def generate_explanation(img_path, model_prediction, confidence):
    prompt = f"""You are an expert neurologist. You are tasked with explaining a saliency map of a brain tumor MRI scan.
    The saliency map was generated by a deep learning model that was trained to classify brain tumors
    as either glioma, meningioma, pituitary, or no tumor.

    The saliency map highlights the regions of the image that the machine learning model is focusing on to make the prediction.

    The deep learning model predicted the image to be of class '{model_prediction}' with a confidence of {confidence * 100}%.

    In your response:
      - Explain what regions of the brain the model is focusing on, based on the saliency map. Refer to the regions highlighted
      in light cyan, those are the ions where the model is focusing on.
      - Explain possible reasons why the model made the prediction it did.
      - Don't mention anything like 'The saliency map highlights the regions the model is focusing on, which are in light cyan'
      in your explanation.
      - Keep your explanation to 4 sentences max.

      Let's think step by step about this. Verify step by step.
    """
    img = PIL.Image.open(img_path)
    model = genai.GenerativeModel(model_name="gemini-1.5-flash")
    response = model.generate_content([prompt, img])
    return response.text

def generate_saliency_map(model, img_array, class_index, img_size, uploaded_file):
    with tf.GradientTape() as tape:
        img_tensor = tf.convert_to_tensor(img_array)
        tape.watch(img_tensor)
        predictions = model(img_tensor)
        target_class = predictions[:, class_index]

    gradients = tape.gradient(target_class, img_tensor)
    gradients = tf.math.abs(gradients)
    gradients = tf.reduce_max(gradients, axis=-1)
    gradients = gradients.numpy().squeeze()
    gradients = cv2.resize(gradients, img_size)

    center = (gradients.shape[0] // 2, gradients.shape[1] // 2)
    radius = min(center[0], center[1]) - 10
    y, x = np.ogrid[:gradients.shape[0], :gradients.shape[1]]
    mask = (x - center[0])**2 + (y - center[1])**2 <= radius**2
    gradients = gradients * mask

    brain_gradients = gradients[mask]
    if brain_gradients.max() > brain_gradients.min():
        brain_gradients = (brain_gradients - brain_gradients.min()) / (brain_gradients.max() - brain_gradients.min())
    gradients[mask] = brain_gradients

    threshold = np.percentile(gradients[mask], 80)
    gradients[gradients < threshold] = 0
    gradients = cv2.GaussianBlur(gradients, (11, 11), 0)

    heatmap = cv2.applyColorMap(np.uint8(255 * gradients), cv2.COLORMAP_JET)
    heatmap = cv2.cvtColor(heatmap, cv2.COLOR_BGR2RGB)
    heatmap = cv2.resize(heatmap, img_size)

    original_img = img_array.squeeze() * 255
    superimposed_img = heatmap * 0.7 + original_img * 0.3
    superimposed_img = superimposed_img.astype(np.uint8)

    saliency_map_path = os.path.join(output_dir, uploaded_file.name)
    cv2.imwrite(saliency_map_path, cv2.cvtColor(superimposed_img, cv2.COLOR_RGB2BGR))

    return superimposed_img, saliency_map_path

def load_model_custom(model_path):
    img_shape = (299, 299, 3)
    
    # Create base model
    base_model = tf.keras.applications.Xception(
        include_top=False, 
        weights="imagenet", 
        input_shape=img_shape, 
        pooling='max'
    )
    
    # Freeze base model layers (important for transfer learning)
    base_model.trainable = False
    
    # Create the model
    model = Sequential([
        base_model,
        Flatten(),
        Dropout(rate=0.3),
        Dense(128, activation='relu'),
        Dropout(rate=0.25),
        Dense(4, activation='softmax')
    ])
    
    # Build the model with proper input shape
    model.build((None,) + img_shape)
    
    # Compile the model BEFORE loading weights
    model.compile(
        optimizer=Adamax(learning_rate=0.001), 
        loss='categorical_crossentropy', 
        metrics=['accuracy', Precision(), Recall()]
    )
    
    try:
        # Load weights
        model.load_weights(model_path)
        print("‚úÖ Model weights loaded successfully!")
        return model
    except Exception as e:
        st.error(f"Error loading model weights: {str(e)}")
        st.error("Please check if the model file exists and is compatible with the current architecture.")
        return None

# Streamlit UI
st.title("üß† Brain Tumor Classification")
st.write("Upload a brain MRI scan to classify and explain using deep learning + Gemini Flash.")

uploaded_file = st.file_uploader("Choose an image...", type=["jpg", "jpeg", "png"])

if uploaded_file:
    selected_model = st.radio("Select Model", ("Transfer Learning - Xception", "Custom CNN"))

    # Load model based on selection
    model = None
    if selected_model == "Transfer Learning - Xception":
        with st.spinner("Loading Xception model..."):
            model = load_model_custom("models/xception_model.weights.h5")
        img_size = (299, 299)
    else:
        try:
            with st.spinner("Loading CNN model..."):
                model = load_model("models/cnn_model.h5")
            img_size = (224, 224)
        except Exception as e:
            st.error(f"Error loading CNN model: {str(e)}")
            model = None

    # Only proceed if model loaded successfully
    if model is not None:
        # Preprocess image
        img = image.load_img(uploaded_file, target_size=img_size)
        img_array = image.img_to_array(img)
        img_array = np.expand_dims(img_array, axis=0) / 255.0

        # Make prediction
        with st.spinner("Making prediction..."):
            prediction = model.predict(img_array)
            class_index = np.argmax(prediction[0])
            result = labels[class_index]

        # Generate saliency map
        with st.spinner("Generating saliency map..."):
            saliency_map, saliency_map_path = generate_saliency_map(
                model, img_array, class_index, img_size, uploaded_file
            )

        # Display results
        col1, col2 = st.columns(2)
        with col1:
            st.image(uploaded_file, caption='Uploaded Image', use_column_width=True)
        with col2:
            st.image(saliency_map, caption='Saliency Map', use_column_width=True)

        st.markdown("### üß™ Classification Results")
        st.markdown(f"""
            <div style="background-color:#000000;padding:30px;border-radius:15px;">
                <div style="display:flex;justify-content:space-between;align-items:center;">
                    <div style="flex:1;text-align:center;">
                        <h3 style="color:#ffffff;">Prediction</h3>
                        <p style="font-size:36px;font-weight:800;color:#FF0000;">{result}</p>
                    </div>
                    <div style="width:2px;height:80px;background-color:#ffffff;"></div>
                    <div style="flex:1;text-align:center;">
                        <h3 style="color:#ffffff;">Confidence</h3>
                        <p style="font-size:36px;font-weight:800;color:#2196F3;">{prediction[0][class_index]:.4%}</p>
                    </div>
                </div>
            </div>
        """, unsafe_allow_html=True)

        # Probability chart
        probabilities = prediction[0]
        sorted_indices = np.argsort(probabilities)[::-1]
        sorted_labels = [labels[i] for i in sorted_indices]
        sorted_probabilities = probabilities[sorted_indices]

        fig = go.Figure(go.Bar(
            x=sorted_probabilities,
            y=sorted_labels,
            orientation='h',
            marker_color=['red' if label == result else 'blue' for label in sorted_labels]
        ))

        fig.update_layout(
            title='Probabilities for each class',
            xaxis_title='Probability',
            yaxis_title='Class',
            height=400,
            width=600,
            yaxis=dict(autorange="reversed")
        )

        st.plotly_chart(fig)

        # Generate explanation
        st.subheader("üí¨ Explanation from Gemini Flash")
        with st.spinner("Generating explanation..."):
            explanation = generate_explanation(saliency_map_path, result, prediction[0][class_index])
            st.write(explanation)
    else:
        st.error("‚ùå Failed to load the selected model. Please check your model files.")
